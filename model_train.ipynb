{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b59fa0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3818f9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'dataset',\n",
    "    image_size = (64,64),\n",
    "    batch_size = 32,\n",
    "    label_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "918bf64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "data = data.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36fbfed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(data))\n",
    "test_size = int(0.2 * len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "456fb3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches: 100\n",
      "Validation batches: 25\n"
     ]
    }
   ],
   "source": [
    "train_ds = data.take(train_size)\n",
    "test_ds = data.skip(train_size)\n",
    "print(f\"Training batches: {train_size}\")\n",
    "print(f\"Validation batches: {test_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5d32e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images loaded: 4000\n"
     ]
    }
   ],
   "source": [
    "total_img = 0\n",
    "for images, labels in data:\n",
    "    total_img +=images.shape[0]\n",
    "print(f\"Total images loaded: {total_img}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "37e45127",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (64,64,3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98bbc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "                loss = 'binary_crossentropy',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef15d1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 61ms/step - accuracy: 0.6488 - loss: 0.6226 - val_accuracy: 0.9775 - val_loss: 0.0898\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.9682 - loss: 0.0825 - val_accuracy: 0.9862 - val_loss: 0.0577\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.9881 - loss: 0.0318 - val_accuracy: 0.9950 - val_loss: 0.0199\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.9962 - loss: 0.0134 - val_accuracy: 0.9950 - val_loss: 0.0171\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.9971 - loss: 0.0106 - val_accuracy: 0.9937 - val_loss: 0.0185\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - accuracy: 0.9938 - loss: 0.0154 - val_accuracy: 0.9825 - val_loss: 0.0438\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.9903 - loss: 0.0356 - val_accuracy: 0.9950 - val_loss: 0.0189\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.9943 - loss: 0.0129 - val_accuracy: 0.9975 - val_loss: 0.0103\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.9984 - loss: 0.0078 - val_accuracy: 0.9987 - val_loss: 0.0051\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - accuracy: 0.9981 - loss: 0.0083 - val_accuracy: 0.9962 - val_loss: 0.0094\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data = test_ds, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6887c2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - accuracy: 0.9962 - loss: 0.0076\n",
      "test_acc:99.75%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "print(f\"test_acc:{test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d60fdd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pillow is installed successfully.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "print(\"Pillow is installed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2dd0b3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 64, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "eyes close\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "img_path = 'D:\\machine_learning\\Drowsiness_detection\\dataset\\closed\\my.jpg'\n",
    "img = Image.open(img_path). resize((64, 64))\n",
    "img = img.convert(\"RGB\")\n",
    "img_array = np.array(img)/ 255.0\n",
    "img_array = np.expand_dims(img_array, axis =0)\n",
    "print(img_array.shape)\n",
    "prediction = model.predict(img_array)\n",
    "if prediction[0] > 0.5:\n",
    "    print(\"eyes open\")\n",
    "else:\n",
    "    print(\"eyes close\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "storefront-4UXBP6qm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
